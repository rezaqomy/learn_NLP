{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b3813d-3949-4547-bfdc-0a42532bdd93",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization\n",
    "and a little pos tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de42d68-acca-4b32-ace0-1aea636f763c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/reza/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/reza/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from hazm import Normalizer\n",
    "from hazm import WordTokenizer\n",
    "from hazm import Stemmer\n",
    "from hazm import Lemmatizer\n",
    "from hazm import POSTagger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b127c924-9faf-45fd-8d52-0faf00fe7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentence = \"Python programmers often tend like programming in python because it's like english. We call people who program in python pythonistas.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487feb7-ec84-461e-8807-779838b36bc5",
   "metadata": {},
   "source": [
    "- stemming & lemmatization in english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d514e92-0fcf-4ecd-a223-a96f406b071c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word : Python               POS tag : NNP\n",
      "word : programmers          POS tag : NNS\n",
      "word : often                POS tag : RB\n",
      "word : tend                 POS tag : VBP\n",
      "word : like                 POS tag : IN\n",
      "word : programming          POS tag : VBG\n",
      "word : in                   POS tag : IN\n",
      "word : python               POS tag : NN\n",
      "word : because              POS tag : IN\n",
      "word : it                   POS tag : PRP\n",
      "word : 's                   POS tag : VBZ\n",
      "word : like                 POS tag : IN\n",
      "word : english              POS tag : JJ\n",
      "word : .                    POS tag : .\n",
      "word : We                   POS tag : PRP\n",
      "word : call                 POS tag : VBP\n",
      "word : people               POS tag : NNS\n",
      "word : who                  POS tag : WP\n",
      "word : program              POS tag : NN\n",
      "word : in                   POS tag : IN\n",
      "word : python               POS tag : NN\n",
      "word : pythonistas          POS tag : NNS\n",
      "word : .                    POS tag : .\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(example_sentence)\n",
    "tages = nltk.pos_tag(tokens)\n",
    "for word, tag in tages:\n",
    "    print(\"word : {0:20} POS tag :\".format(word), tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c347f4c4-aeb3-4658-8d56-058d60eb9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e385b294-9054-46f7-a649-119376f76723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmer       : Python              -> python\n",
      "lemmatization : Python              -> Python\n",
      "\n",
      "stemmer       : programmers         -> programm\n",
      "lemmatization : programmers         -> programmer\n",
      "\n",
      "stemmer       : often               -> often\n",
      "lemmatization : often               -> often\n",
      "\n",
      "stemmer       : tend                -> tend\n",
      "lemmatization : tend                -> tend\n",
      "\n",
      "stemmer       : like                -> like\n",
      "lemmatization : like                -> like\n",
      "\n",
      "stemmer       : programming         -> program\n",
      "lemmatization : programming         -> program\n",
      "\n",
      "stemmer       : in                  -> in\n",
      "lemmatization : in                  -> in\n",
      "\n",
      "stemmer       : python              -> python\n",
      "lemmatization : python              -> python\n",
      "\n",
      "stemmer       : because             -> becaus\n",
      "lemmatization : because             -> because\n",
      "\n",
      "stemmer       : it                  -> it\n",
      "lemmatization : it                  -> it\n",
      "\n",
      "stemmer       : 's                  -> 's\n",
      "lemmatization : 's                  -> 's\n",
      "\n",
      "stemmer       : like                -> like\n",
      "lemmatization : like                -> like\n",
      "\n",
      "stemmer       : english             -> english\n",
      "lemmatization : english             -> english\n",
      "\n",
      "stemmer       : .                   -> .\n",
      "lemmatization : .                   -> .\n",
      "\n",
      "stemmer       : We                  -> we\n",
      "lemmatization : We                  -> We\n",
      "\n",
      "stemmer       : call                -> call\n",
      "lemmatization : call                -> call\n",
      "\n",
      "stemmer       : people              -> peopl\n",
      "lemmatization : people              -> people\n",
      "\n",
      "stemmer       : who                 -> who\n",
      "lemmatization : who                 -> who\n",
      "\n",
      "stemmer       : program             -> program\n",
      "lemmatization : program             -> program\n",
      "\n",
      "stemmer       : in                  -> in\n",
      "lemmatization : in                  -> in\n",
      "\n",
      "stemmer       : python              -> python\n",
      "lemmatization : python              -> python\n",
      "\n",
      "stemmer       : pythonistas         -> pythonista\n",
      "lemmatization : pythonistas         -> pythonistas\n",
      "\n",
      "stemmer       : .                   -> .\n",
      "lemmatization : .                   -> .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "porterStemmer = PorterStemmer()\n",
    "wordNetLemmatizer = WordNetLemmatizer()\n",
    "for word, tag in tages:\n",
    "    print(\"stemmer       : {0:20}->\".format(word), porterStemmer.stem(word))\n",
    "    print(\"lemmatization : {0:20}->\".format(word), wordNetLemmatizer.lemmatize(word, get_wordnet_pos(tag)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba3ed1b-718e-4383-8a6d-917f399982b6",
   "metadata": {},
   "source": [
    "- stemming & lemmatization in persian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ec49843-7829-44f6-9fa3-51bfdc12d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_persian_sentence = \"نور خورشید به سختی از میان برگ‌های انبوه درختان کهنسال به زمین نفوذ می‌کرد و سایه‌ای خنک و دل‌انگیز بر بستر جنگل گسترانده بود.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88fd6042-b1ea-4ad9-b4e1-b69a65e9afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordTokenizer = WordTokenizer()\n",
    "normalizer = Normalizer()\n",
    "normalized_text = normalizer.normalize(example_persian_sentence)\n",
    "words = wordTokenizer.tokenize(normalized_text)\n",
    "tagger = POSTagger(model='pos_tagger.model')\n",
    "words_with_tag = tagger.tag(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "310c120c-d3e9-47de-aa7a-f2f971a400e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmer       : نور                 -> نور\n",
      "lemmatization : نور                 -> نور\n",
      "\n",
      "stemmer       : خورشید              -> خورشید\n",
      "lemmatization : خورشید              -> خورشید\n",
      "\n",
      "stemmer       : به                  -> به\n",
      "lemmatization : به                  -> به\n",
      "\n",
      "stemmer       : سختی                -> سخت\n",
      "lemmatization : سختی                -> سختی\n",
      "\n",
      "stemmer       : از                  -> از\n",
      "lemmatization : از                  -> از\n",
      "\n",
      "stemmer       : میان                -> م\n",
      "lemmatization : میان                -> میان\n",
      "\n",
      "stemmer       : برگ‌های             -> برگ\n",
      "lemmatization : برگ‌های             -> برگ\n",
      "\n",
      "stemmer       : انبوه               -> انبوه\n",
      "lemmatization : انبوه               -> انبوه\n",
      "\n",
      "stemmer       : درختان              -> درخ\n",
      "lemmatization : درختان              -> درختان\n",
      "\n",
      "stemmer       : کهنسال              -> کهنسال\n",
      "lemmatization : کهنسال              -> کهنسال\n",
      "\n",
      "stemmer       : به                  -> به\n",
      "lemmatization : به                  -> به\n",
      "\n",
      "stemmer       : زمین                -> زمین\n",
      "lemmatization : زمین                -> زمین\n",
      "\n",
      "stemmer       : نفوذ                -> نفوذ\n",
      "lemmatization : نفوذ                -> نفوذ\n",
      "\n",
      "stemmer       : می‌کرد              -> می‌کرد\n",
      "lemmatization : می‌کرد              -> می‌کرد\n",
      "\n",
      "stemmer       : و                   -> و\n",
      "lemmatization : و                   -> و\n",
      "\n",
      "stemmer       : سایه‌ای             -> سایه\n",
      "lemmatization : سایه‌ای             -> سایه\n",
      "\n",
      "stemmer       : خنک                 -> خنک\n",
      "lemmatization : خنک                 -> خنک\n",
      "\n",
      "stemmer       : و                   -> و\n",
      "lemmatization : و                   -> و\n",
      "\n",
      "stemmer       : دل‌انگیز            -> دل‌انگیز\n",
      "lemmatization : دل‌انگیز            -> دل‌انگیز\n",
      "\n",
      "stemmer       : بر                  -> بر\n",
      "lemmatization : بر                  -> بر\n",
      "\n",
      "stemmer       : بستر                -> بس\n",
      "lemmatization : بستر                -> بستر\n",
      "\n",
      "stemmer       : جنگل                -> جنگل\n",
      "lemmatization : جنگل                -> جنگل\n",
      "\n",
      "stemmer       : گسترانده_بود        -> گسترانده_بود\n",
      "lemmatization : گسترانده_بود        -> گسترانده_بود\n",
      "\n",
      "stemmer       : .                   -> .\n",
      "lemmatization : .                   -> .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persian_stemmer = Stemmer()\n",
    "persian_lemmatizer = Lemmatizer()\n",
    "for word, tag in words_with_tag:\n",
    "    print(\"stemmer       : {0:20}->\".format(word), persian_stemmer.stem(word))\n",
    "    print(\"lemmatization : {0:20}->\".format(word), persian_lemmatizer.lemmatize(word, get_wordnet_pos(tag)))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
